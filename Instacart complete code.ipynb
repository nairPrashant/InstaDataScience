{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: \n",
    "* To predict which products will be in a user's next order \n",
    "* To predict which Users will try  it for the first time.\n",
    "* To predict which users will Add  particular products to cart next during a session.\n",
    "\n",
    "The goal of the competition is to predict, for each individual, which products that they have purchased before they will purchase again in their final order.For the training set, we are given the participants' final order. For the training set, we are given the time and day of their final order, but not the products they ordered.\n",
    "\n",
    "Predictions for the competition are submitted as an order ID and a list of product IDs predicted for that order. Predictions can include None, a special product ID indicating that no previously ordered products have been ordered. None can be combined with other product IDs in prediction, but will of course only occur on its own in the ground truth.\n",
    "\n",
    "Predictions are evaluated using the average F1-score across orders.\n",
    "\n",
    "### Data Dimensions: The dataset is anonymized and contains a sample of over 3 million grocery orders from more                                        than 200,000 Instacart users.\n",
    "\n",
    "* The only information provided about users is their sequence of orders and the products in those orders\n",
    "* All of the IDs in the dataset are entirely randomized, and cannot be linked back to any other ID\n",
    "* Only products that are bought by multiple people at multiple retailers are included, and no retailer ID is provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing  all Necessary Modules for data exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cede2774bab8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;31m# linear algebra\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[1;31m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ANACONDA\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpackages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_newdocs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     __all__ = ['add_newdocs',\n\u001b[0;32m    144\u001b[0m                \u001b[1;34m'ModuleDeprecationWarning'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ANACONDA\\lib\\site-packages\\numpy\\add_newdocs.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_newdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m###############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ANACONDA\\lib\\site-packages\\numpy\\lib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtype_check\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mindex_tricks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfunction_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ANACONDA\\lib\\site-packages\\numpy\\lib\\type_check.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m            'common_type']\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumeric\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumeric\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mobj2sctype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ANACONDA\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menvkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0menv_added\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0menvkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv_added\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menvkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "#changing  to current working directory\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\x189613\\\\Documents\\\\Personal\\\\APDS\\\\Instacart\\\\data\\\\dataForJupyter')\n",
    "#Verifying if current directory is changed or not\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading all the necessary CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_products_train_df =pd.read_csv(\"order_products__train.csv\",sep=',',dtype={'order_id':int, 'product_id':int,'add_to_cart_order':'int8','reordered':'int8'})\n",
    "\n",
    "order_products_prior_df =pd.read_csv(\"order_products__prior.csv\", sep=',',dtype={'order_id':'uint32', 'product_id':'uint16','add_to_cart_order':'int8','reordered':'int8'})\n",
    "\n",
    "orders_df = pd.read_csv(\"orders.csv\",sep=',',dtype={'order_id':'uint32','user_id':'uint32','order_number':'uint8','order_dow':'uint8','order_hour_of_day':'uint8'})\n",
    "\n",
    "products_df = pd.read_csv(\"products.csv\",dtype={'product_id':'uint16','aisle_id':'uint8','department_id':'uint8'})\n",
    "aisles_df = pd.read_csv(\"aisles.csv\",dtype={'aisle_id':int})\n",
    "departments_df = pd.read_csv(\"departments.csv\",dtype={'department_id':int})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('order_products_train_df***********************************************************************************')\n",
    "order_products_train_df.info(memory_usage='deep')\n",
    "print('order_products_prior_df***********************************************************************************')\n",
    "order_products_prior_df.info()\n",
    "print('orders_df***********************************************************************************')\n",
    "orders_df.info(memory_usage='deep')\n",
    "print('products_df***********************************************************************************')\n",
    "products_df.info(memory_usage='deep')\n",
    "print('aisles_df***********************************************************************************')\n",
    "aisles_df.info(memory_usage='deep')\n",
    "print('departments_df***********************************************************************************')\n",
    "departments_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the  head of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checking the variables in each of files imported \n",
    "print(order_products_train_df.head(2))\n",
    "print('***********************************************************************************')\n",
    "print(order_products_prior_df.head(20))\n",
    "print('**********************************************************************************')\n",
    "print(orders_df.head(2))\n",
    "print('**********************************************************************************')\n",
    "print(products_df.head(2))\n",
    "print('**********************************************************************************')\n",
    "print(aisles_df.head(2))\n",
    "print('**********************************************************************************')\n",
    "print(departments_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# orders_df has a mapping of train , test and Prior \n",
    "cnt_srs = orders_df.eval_set.value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[4])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Eval set type', fontsize=12)\n",
    "plt.title('Count of rows in each dataset', fontsize=15)\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('DELETE: for testing')\n",
    "print(orders_df.head(10))\n",
    "cnt_srs = orders_df.groupby(\"user_id\")[\"order_number\"].aggregate(np.max).reset_index()\n",
    "cnt_srs.head(4)\n",
    "#cnt_srs = cnt_srs.order_number.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Maximum Order Count  VS  Frequency \n",
    "# It tells ,  how many  maximum orders user have done overall. So there are no Orders Less than 4 and Maximum is capped at 100\n",
    "cnt_srs = orders_df.groupby(\"user_id\")[\"order_number\"].aggregate(np.max).reset_index()\n",
    "cnt_srs = cnt_srs.order_number.value_counts()\n",
    "\n",
    "plt.figure(figsize=(24,12))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[2])\n",
    "plt.ylabel('Number of Occurrences/customers', fontsize=20)\n",
    "plt.xlabel('Maximum order number', fontsize=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"No. of Customers w.r.t Max orders\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which Day of week , more orders were made.Maximum were made on Weekends. Low's are on Wednesday \n",
    "plt.figure(figsize=(12,8))\n",
    "sns.countplot(x=\"order_dow\", data=orders_df, color=color[5])\n",
    "plt.ylabel('Count of orders', fontsize=12)\n",
    "plt.xlabel('Day of week', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Frequency of order by week day\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which hour of day , more orders came during day time \n",
    "plt.figure(figsize=(12,8))\n",
    "sns.countplot(x=\"order_hour_of_day\", data=orders_df, color=color[3])\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Hour of day', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Frequency of order by hour of day\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combining Day of week and Hour of day , we found that , Sat and sundays during day time are more happening wrt orders.\n",
    "grouped_df = orders_df.groupby([\"order_dow\", \"order_hour_of_day\"])[\"order_number\"].aggregate(\"count\").reset_index()\n",
    "grouped_df = grouped_df.pivot('order_dow', 'order_hour_of_day', 'order_number')\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(grouped_df)\n",
    "plt.title(\"Frequency of Day of week Vs Hour of day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many days since last . Abrupt rise in Peaks  at 7 days, 14 days, 30 days. (looks like it is capped at 30 days)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.countplot(x=\"days_since_prior_order\", data=orders_df, color=color[1])\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Days since prior order', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Frequency distribution by days since prior order\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#percentage of ordered products in the prior set \n",
    "order_products_prior_df.reordered.sum()/order_products_prior_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# percentage of ordered products in the train set\n",
    "# Approxmiately 60% of products in order are reordered  in Training set\n",
    "order_products_train_df.reordered.sum()/order_products_train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_df =order_products_prior_df.groupby(\"order_id\")[\"reordered\"].aggregate(\"sum\").reset_index()\n",
    "grouped_df[\"reordered\"].loc[grouped_df[\"reordered\"]>1] = 1\n",
    "grouped_df.reordered.value_counts() / grouped_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# About 12% of the orders in prior set has no re-ordered items while in the train set it is 6.5%.\n",
    "grouped_df = order_products_train_df.groupby(\"order_id\")[\"reordered\"].aggregate(\"sum\").reset_index()\n",
    "grouped_df[\"reordered\"].loc[grouped_df[\"reordered\"]>1] = 1\n",
    "grouped_df.reordered.value_counts() / grouped_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A right tailed distribution with the maximum value at 5\n",
    "grouped_df = order_products_train_df.groupby(\"order_id\")[\"add_to_cart_order\"].aggregate(\"max\").reset_index()\n",
    "cnt_srs = grouped_df.add_to_cart_order.value_counts()\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8,color=color[2])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Number of products in the given order', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Distribution of no. of products in an order\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERGING  Product_details with Order_prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging \n",
    "order_products_prior_df = pd.merge(order_products_prior_df, products_df, on='product_id', how='left')\n",
    "order_products_prior_df = pd.merge(order_products_prior_df, aisles_df, on='aisle_id', how='left')\n",
    "order_products_prior_df = pd.merge(order_products_prior_df, departments_df, on='department_id', how='left')\n",
    "order_products_prior_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_products_prior_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Most of them are organic  with more bought percentage.\n",
    "cnt_srs = order_products_prior_df['product_name'].value_counts().reset_index().head(20)\n",
    "cnt_srs.columns = ['product_name', 'frequency_count']\n",
    "cnt_srs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Most Important Aisles \n",
    "cnt_srs = order_products_prior_df['aisle'].value_counts().head(20)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[2])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Aisle', fontsize=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Department Wise Distribution\n",
    "plt.figure(figsize=(10,10))\n",
    "temp_series = order_products_prior_df['department'].value_counts()\n",
    "labels = (np.array(temp_series.index))\n",
    "sizes = (np.array((temp_series / temp_series.sum())*100))\n",
    "plt.pie(sizes, labels=labels,autopct='%1.1f%%', startangle=200)\n",
    "plt.title(\"Departments distribution\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which Departments had more reordered items.?\n",
    "grouped_df = order_products_prior_df.groupby([\"department\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.pointplot(grouped_df['department'].values, grouped_df['reordered'].values, alpha=0.8, color=color[2])\n",
    "plt.ylabel('Reorder ratio', fontsize=12)\n",
    "plt.xlabel('Department', fontsize=12)\n",
    "plt.title(\"Department wise reorder ratio\", fontsize=15)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which Department+Aisles had more reordered ratio \n",
    "grouped_df = order_products_prior_df.groupby([\"department_id\", \"aisle\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
    "fig, ax = plt.subplots(figsize=(12,20))\n",
    "ax.scatter(grouped_df.reordered.values, grouped_df.department_id.values)\n",
    "for i, txt in enumerate(grouped_df.aisle.values):\n",
    "    ax.annotate(txt, (grouped_df.reordered.values[i], grouped_df.department_id.values[i]), rotation=45,ha='center', va='center', color='green')\n",
    "plt.xlabel('Reorder Ratio')\n",
    "plt.ylabel('department_id')\n",
    "plt.title(\"Reorder ratio of different aisles\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let us now explore the relationship between how order of adding the product to the cart affects the reorder ratio\n",
    "\n",
    "#Looks like the products that are added to the cart initially are more likely to be reordered again compared to the \n",
    "#ones added later.\n",
    "order_products_prior_df[\"add_to_cart_order_mod\"] = order_products_prior_df[\"add_to_cart_order\"].copy()\n",
    "order_products_prior_df[\"add_to_cart_order_mod\"].loc[order_products_prior_df[\"add_to_cart_order_mod\"]>70] = 70\n",
    "grouped_df = order_products_prior_df.groupby([\"add_to_cart_order_mod\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.pointplot(grouped_df['add_to_cart_order_mod'].values, grouped_df['reordered'].values, alpha=0.8, color=color[2])\n",
    "plt.ylabel('Reorder ratio', fontsize=12)\n",
    "plt.xlabel('Add to cart order', fontsize=12)\n",
    "plt.title(\"Add to cart order - Reorder ratio\", fontsize=15)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# At that times during the complete day , Reorder ration was maximum ?\n",
    "order_products_train_df = pd.merge(order_products_train_df, orders_df, on='order_id', how='left')\n",
    "grouped_df = order_products_train_df.groupby([\"order_dow\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(grouped_df['order_dow'].values, grouped_df['reordered'].values, alpha=0.8, color=color[2])\n",
    "plt.ylabel('Reorder ratio', fontsize=12)\n",
    "plt.xlabel('Day of week', fontsize=12)\n",
    "plt.title(\"Reorder ratio across day of week\", fontsize=15)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylim(0.5, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reordered ration across hours of day. \n",
    "grouped_df = order_products_train_df.groupby([\"order_hour_of_day\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(grouped_df['order_hour_of_day'].values, grouped_df['reordered'].values, alpha=0.8, color=color[4])\n",
    "plt.ylabel('Reorder ratio', fontsize=12)\n",
    "plt.xlabel('Hour of day', fontsize=12)\n",
    "plt.title(\"Reorder ratio across hour of day\", fontsize=15)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylim(0.5, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reordered ratio at particular time on particular day. It was at peek ,on weekends day times or early morning.\n",
    "grouped_df = order_products_train_df.groupby([\"order_dow\", \"order_hour_of_day\"])[\"reordered\"].aggregate(\"mean\").reset_index()\n",
    "grouped_df = grouped_df.pivot('order_dow', 'order_hour_of_day', 'reordered')\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(grouped_df)\n",
    "plt.title(\"Reorder ratio of Day of week Vs Hour of day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "The raw data is spread across 7 tables, and isn't amenable to standard classification algorithms. To create a tractable data set, I built a table with a row for each (individual, product) combination that occurs in the prior orders, and constructed a set of features based on the attributes and order history of the individual, the product, and the (individual, product) combination. Along with these features was included a target column indicating whether the individual in fact ordered the given product in their final order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IDIR = 'D:\\\\Kaggle_Compi\\\\Insta_cart\\\\instacart_online_grocery_shopping_2017_05_01\\\\Data\\\\Data_all\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('loading prior')\n",
    "priors = pd.read_csv(IDIR + 'order_products__prior.csv', dtype={\n",
    "            'order_id': np.int32,\n",
    "            'product_id': np.uint16,\n",
    "            'add_to_cart_order': np.int16,\n",
    "            'reordered': np.int8})\n",
    "\n",
    "print('loading train')\n",
    "train = pd.read_csv(IDIR + 'order_products__train.csv', dtype={\n",
    "            'order_id': np.int32,\n",
    "            'product_id': np.uint16,\n",
    "            'add_to_cart_order': np.int16,\n",
    "            'reordered': np.int8})\n",
    "\n",
    "print('loading orders')\n",
    "orders = pd.read_csv(IDIR + 'orders.csv', dtype={\n",
    "        'order_id': np.int32,\n",
    "        'user_id': np.int32,\n",
    "        'eval_set': 'category',\n",
    "        'order_number': np.int16,\n",
    "        'order_dow': np.int8,\n",
    "        'order_hour_of_day': np.int8,\n",
    "        'days_since_prior_order': np.float32})\n",
    "\n",
    "print('loading products')\n",
    "products = pd.read_csv(IDIR + 'products.csv', dtype={\n",
    "        'product_id': np.uint16,\n",
    "        'order_id': np.int32,\n",
    "        'aisle_id': np.uint8,\n",
    "        'department_id': np.uint8},\n",
    "        usecols=['product_id', 'aisle_id', 'department_id'])\n",
    "\n",
    "print('priors {}: {}'.format(priors.shape, ', '.join(priors.columns)))\n",
    "print('orders {}: {}'.format(orders.shape, ', '.join(orders.columns)))\n",
    "print('train {}: {}'.format(train.shape, ', '.join(train.columns)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing  for Modelling framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### \n",
    "print('computing product f')\n",
    "prods = pd.DataFrame()\n",
    "prods['orders'] = priors.groupby(priors.product_id).size().astype(np.int32)\n",
    "prods['reorders'] = priors['reordered'].groupby(priors.product_id).sum().astype(np.float32)\n",
    "prods['reorder_rate'] = (prods.reorders / prods.orders).astype(np.float32)\n",
    "products = products.join(prods, on='product_id')\n",
    "products.set_index('product_id', drop=False, inplace=True)\n",
    "del prods\n",
    "\n",
    "\n",
    "print('add order info to priors')\n",
    "orders.set_index('order_id', inplace=True, drop=False)\n",
    "priors = priors.join(orders, on='order_id', rsuffix='_')\n",
    "priors.drop('order_id_', inplace=True, axis=1)\n",
    "\n",
    "### user features\n",
    "\n",
    "\n",
    "print('computing user f')\n",
    "usr = pd.DataFrame()\n",
    "usr['average_days_between_orders'] = orders.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\n",
    "usr['nb_orders'] = orders.groupby('user_id').size().astype(np.int16)\n",
    "\n",
    "users = pd.DataFrame()\n",
    "users['total_items'] = priors.groupby('user_id').size().astype(np.int16)\n",
    "users['all_products'] = priors.groupby('user_id')['product_id'].apply(set)\n",
    "users['total_distinct_items'] = (users.all_products.map(len)).astype(np.int16)\n",
    "\n",
    "users = users.join(usr)\n",
    "del usr\n",
    "users['average_basket'] = (users.total_items / users.nb_orders).astype(np.float32)\n",
    "print('user f', users.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### userXproduct features\n",
    "\n",
    "print('compute userXproduct f - this is long...')\n",
    "priors['user_product'] = priors.product_id + priors.user_id * 100000\n",
    "\n",
    "# This was to slow !!\n",
    "#def last_order(order_group):\n",
    "#    ix = order_group.order_number.idxmax\n",
    "#    return order_group.shape[0], order_group.order_id[ix],  order_group.add_to_cart_order.mean()\n",
    "#userXproduct = pd.DataFrame()\n",
    "#userXproduct['tmp'] = df.groupby('user_product').apply(last_order)\n",
    "\n",
    "d= dict()\n",
    "for row in priors.itertuples():\n",
    "    z = row.user_product\n",
    "    if z not in d:\n",
    "        d[z] = (1,\n",
    "                (row.order_number, row.order_id),\n",
    "                row.add_to_cart_order)\n",
    "    else:\n",
    "        d[z] = (d[z][0] + 1,\n",
    "                max(d[z][1], (row.order_number, row.order_id)),\n",
    "                d[z][2] + row.add_to_cart_order)\n",
    "\n",
    "print('to dataframe (less memory)')\n",
    "userXproduct = pd.DataFrame.from_dict(d, orient='index')\n",
    "del d\n",
    "userXproduct.columns = ['nb_orders', 'last_order_id', 'sum_pos_in_cart']\n",
    "userXproduct.nb_orders = userXproduct.nb_orders.astype(np.int16)\n",
    "userXproduct.last_order_id = userXproduct.last_order_id.map(lambda x: x[1]).astype(np.int32)\n",
    "userXproduct.sum_pos_in_cart = userXproduct.sum_pos_in_cart.astype(np.int16)\n",
    "print('user X product f', len(userXproduct))\n",
    "\n",
    "del priors\n",
    "\n",
    "### train / test orders ###\n",
    "print('split orders : train, test')\n",
    "test_orders = orders[orders.eval_set == 'test']\n",
    "train_orders = orders[orders.eval_set == 'train']\n",
    "\n",
    "train.set_index(['order_id', 'product_id'], inplace=True, drop=False)\n",
    "\n",
    "### build list of candidate products to reorder, with features ###\n",
    "\n",
    "def features(selected_orders, labels_given=False):\n",
    "    print('build candidate list')\n",
    "    order_list = []\n",
    "    product_list = []\n",
    "    labels = []\n",
    "    i=0\n",
    "    for row in selected_orders.itertuples():\n",
    "        i+=1\n",
    "        if i%10000 == 0: print('order row',i)\n",
    "        order_id = row.order_id\n",
    "        user_id = row.user_id\n",
    "        user_products = users.all_products[user_id]\n",
    "        product_list += user_products\n",
    "        order_list += [order_id] * len(user_products)\n",
    "        if labels_given:\n",
    "            labels += [(order_id, product) in train.index for product in user_products]\n",
    "        \n",
    "    df = pd.DataFrame({'order_id':order_list, 'product_id':product_list}, dtype=np.int32)\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    del product_list\n",
    "    \n",
    "    print('user related features')\n",
    "    df['user_id'] = df.order_id.map(orders.user_id)\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_orders)\n",
    "    df['user_total_items'] = df.user_id.map(users.total_items)\n",
    "    df['total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n",
    "    df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n",
    "    df['user_average_basket'] =  df.user_id.map(users.average_basket)\n",
    "    \n",
    "    print('order related features')\n",
    "    # df['dow'] = df.order_id.map(orders.order_dow)\n",
    "    df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n",
    "    df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n",
    "    df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n",
    "    \n",
    "    print('product related features')\n",
    "    df['aisle_id'] = df.product_id.map(products.aisle_id)\n",
    "    df['department_id'] = df.product_id.map(products.department_id)\n",
    "    df['product_orders'] = df.product_id.map(products.orders).astype(np.int32)\n",
    "    df['product_reorders'] = df.product_id.map(products.reorders)\n",
    "    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n",
    "\n",
    "    print('user_X_product related features')\n",
    "    df['z'] = df.user_id * 100000 + df.product_id\n",
    "    df.drop(['user_id'], axis=1, inplace=True)\n",
    "    df['UP_orders'] = df.z.map(userXproduct.nb_orders)\n",
    "    df['UP_orders_ratio'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_last_order_id'] = df.z.map(userXproduct.last_order_id)\n",
    "    df['UP_average_pos_in_cart'] = (df.z.map(userXproduct.sum_pos_in_cart) / df.UP_orders).astype(np.float32)\n",
    "    df['UP_reorder_rate'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_orders_since_last'] = df.user_total_orders - df.UP_last_order_id.map(orders.order_number)\n",
    "    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - df.UP_last_order_id.map(orders.order_hour_of_day)).map(lambda x: min(x, 24-x)).astype(np.int8)\n",
    "    #df['UP_same_dow_as_last_order'] = df.UP_last_order_id.map(orders.order_dow) == \\\n",
    "    #                                              df.order_id.map(orders.order_dow)\n",
    "\n",
    "    df.drop(['UP_last_order_id', 'z'], axis=1, inplace=True)\n",
    "    print(df.dtypes)\n",
    "    print(df.memory_usage())\n",
    "    return (df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Training the Model ( Light GBM) and  testing it on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, labels = features(train_orders, labels_given=True)\n",
    "\n",
    "f_to_use = ['user_total_orders', 'user_total_items', 'total_distinct_items',\n",
    "       'user_average_days_between_orders', 'user_average_basket',\n",
    "       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n",
    "       'aisle_id', 'department_id', 'product_orders', 'product_reorders',\n",
    "       'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n",
    "       'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n",
    "       'UP_delta_hour_vs_last'] # 'dow', 'UP_same_dow_as_last_order'\n",
    "\n",
    "\n",
    "print('formating for lgb')\n",
    "d_train = lgb.Dataset(df_train[f_to_use],\n",
    "                      label=labels,\n",
    "                      categorical_feature=['aisle_id', 'department_id'])  # , 'order_hour_of_day', 'dow'\n",
    "del df_train\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 100\n",
    "\n",
    "print('light GBM train :-)')\n",
    "bst = lgb.train(params, d_train, ROUNDS)\n",
    "# lgb.plot_importance(bst, figsize=(9,20))\n",
    "del d_train\n",
    "\n",
    "### build candidates list for test ###\n",
    "\n",
    "df_test, _ = features(test_orders)\n",
    "\n",
    "print('light GBM predict')\n",
    "preds = bst.predict(df_test[f_to_use])\n",
    "\n",
    "df_test['pred'] = preds\n",
    "\n",
    "TRESHOLD = 0.22  # guess, should be tuned with crossval on a subset of train data\n",
    "\n",
    "d = dict()\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred > TRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "\n",
    "for order in test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "\n",
    "sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = ['order_id', 'products']\n",
    "sub.to_csv('sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
